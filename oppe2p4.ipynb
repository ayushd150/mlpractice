{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d0be4c9",
   "metadata": {},
   "source": [
    "Data preproccessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "6d71a556",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "771ea10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "8c0d70b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Copy of V1 (pre).csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33939e85",
   "metadata": {},
   "source": [
    "How many total number of rows and columns are there in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "8b63dd66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 15)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c86994",
   "metadata": {},
   "source": [
    "Is there any Missing values in the given dataset ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "6c8c274f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sum()\n",
    "df.isna().sum().sum() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cf328c",
   "metadata": {},
   "source": [
    "Check all \" ?\" symbol in the dataset and replace it with \"np.nan\" value . Which of the columns in the dataset have null values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "f50e9ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               False\n",
       "workclass         False\n",
       "fnlwgt            False\n",
       "education         False\n",
       "education-num     False\n",
       "marital-status    False\n",
       "occupation        False\n",
       "relationship      False\n",
       "race              False\n",
       "sex               False\n",
       "capital-gain      False\n",
       "capital-loss      False\n",
       "hours-per-week    False\n",
       "native-country    False\n",
       "IncomeGroup       False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.replace(\" ?\", np.nan)\n",
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7542b0",
   "metadata": {},
   "source": [
    "What fraction of total samples (in percentage) have missing value in occupation column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "d06b96df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(5.7)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['occupation'].replace(\" ?\", np.nan).isnull().mean()*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a760843",
   "metadata": {},
   "source": [
    " What fraction of total samples(In percentage) have income <= 50k in the given dataset? (round the value upto 2 decimal places)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "7b455783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(76.51)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['IncomeGroup'].eq(\" <=50K\").mean() * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2043ea34",
   "metadata": {},
   "source": [
    "What is the mean age of the samples given in the dataset(mark the closest integer from the given options)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "f434987e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(38.553)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = df.age.mean()\n",
    "mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6aa4045",
   "metadata": {},
   "source": [
    "How many people have completed their education upto \"Preschool\" only ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "2dbf237e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' 7th-8th', ' 11th', ' Bachelors', ' HS-grad', ' Some-college',\n",
       "       ' Masters', ' Assoc-voc', ' Doctorate', ' 5th-6th', ' 10th',\n",
       "       ' 12th', ' Assoc-acdm', ' Prof-school', ' 9th', ' 1st-4th',\n",
       "       ' Preschool'], dtype=object)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.education.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "a1404a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_preschool = df[df['education'] == ' Preschool'].shape[0]\n",
    "count_preschool\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f62f0f",
   "metadata": {},
   "source": [
    "What is the correlation cofficient between column \"education-num\" and column \"capital-gain\" ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "294d4c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.12456727883397221)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_value = df['education-num'].corr(df['capital-gain'])\n",
    "corr_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e519d123",
   "metadata": {},
   "source": [
    "Apply SimpleImputer with strategy = 'most_frequent' to replace all NaN value by mode of respective column in the original dataset.(Use this updated dataset only for all further questions)\n",
    "Q10. What is the mode of 'occupation' column of updated datset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "e4d28c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Prof-specialty\n"
     ]
    }
   ],
   "source": [
    "st = SimpleImputer(strategy='most_frequent')\n",
    "st.fit_transform(df)\n",
    "occ = df.occupation.mode()[0]\n",
    "print(occ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f81f57",
   "metadata": {},
   "source": [
    "Split the dataset into X1, X2 and y, where X1 contains all Numerical features, X2 contains all categorical features(except \"IncomeGroup\") and save 'IncomeGroup' column in y variable. Then apply OneHotEncoder on the categorical features(X2) with option (sparse = False) and StandardScaler on the numerical features (X2).\n",
    "Q11. What is the total number of columns in X1 and X2 variables respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "31a73135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('IncomeGroup', axis=1)\n",
    "y = df['IncomeGroup']\n",
    "numeric_cols = X.select_dtypes(exclude=\"object\").columns\n",
    "categorical_cols = X.select_dtypes(include=\"object\").columns\n",
    "\n",
    "X1 = X[numeric_cols]     \n",
    "X2 = X[categorical_cols]      \n",
    "\n",
    "print(len(X1.columns))\n",
    "print(len(X2.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bc731b",
   "metadata": {},
   "source": [
    "Apply StandardScaler on the X1 data and OneHotEncoder on X2 data with option (sparse = False).\n",
    "Q12. What are the data types of X1 and X2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "d20ff684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X1_scaled = scaler.fit_transform(X1)\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "X2_encoded = encoder.fit_transform(X2)\n",
    "\n",
    "print(type(X1_scaled))\n",
    "print(type(X2_encoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630a2c13",
   "metadata": {},
   "source": [
    "Concatenate X1 and X2 and call it X( Keep axis = 1) and then Convert X to a dataframe.\n",
    "Q13. What is the new shape of resultant X?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "ea61068f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 108)\n"
     ]
    }
   ],
   "source": [
    "X = np.concatenate([X1_scaled, X2_encoded], axis=1)\n",
    "X = pd.DataFrame(X)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfde4a0",
   "metadata": {},
   "source": [
    "Model Building\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd212c9c",
   "metadata": {},
   "source": [
    " Split the dataset into training and validation dataset into 80:20 ratio while keeping random_state =64. what is the shape of the y_train dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "88ccece1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000,)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=64)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf6c39d",
   "metadata": {},
   "source": [
    "Instantiate a perceptron classifier that with following parameters:\n",
    "Fit the intercept\n",
    "Put warm start to be False\n",
    "Fit this perceptron model with the training dataset and calculate the accuracy score for training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "51072c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8055"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per = Perceptron(fit_intercept=True, warm_start=False)\n",
    "per.fit(X_train, y_train)\n",
    "y_pred=per.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c812880b",
   "metadata": {},
   "source": [
    "Q16. Create a new Perceptron(random_state=42) object with given settings in the instrunctions and train it on training set . What is the value of bias (intercept) (upto 1 decimal point) ?\n",
    "Set early stopping and fit intercept to be True\n",
    "Put warm start to be False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "06ae3d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-8.])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per1 = Perceptron(random_state=42, early_stopping=True, fit_intercept=True, warm_start=False)\n",
    "per1.fit(X_train, y_train)\n",
    "per1.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25003d8",
   "metadata": {},
   "source": [
    "Use SGDClassifier on the training dataset (X_train and y_train) to train the model. Use the following parameters:\n",
    "log is the loss function to be used\n",
    "apply ridge regularization,\n",
    "maximum number of passes over the training data is 10\n",
    "initial learning rate is 0.01,\n",
    "regularization rate value is 0.001,\n",
    "learning rate should not change during training.\n",
    "Take random_state=64.\n",
    "Set warm_state as False\n",
    "Note : Please ignore the convergence warning.\n",
    "\n",
    "Q17. Based on this operation, calculate and enter the correct value of accuracy (Upto 4 decimal points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "bdf07527",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "dcaaab62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KIIT0001\\OneDrive\\Desktop\\mlpractice\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.849"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd = SGDClassifier(loss='log_loss', penalty='l2', max_iter=10, eta0=0.01, alpha=0.001, learning_rate='constant', random_state=64, warm_start=False)\n",
    "sgd.fit(X_train, y_train)\n",
    "y_pred = sgd.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4898ec2",
   "metadata": {},
   "source": [
    "Take LogisticRegression estimator with following parameters for fitting on the training dataset:\n",
    "Use sag as solver\n",
    "Set random state to be equal to 64\n",
    "Tolerance for stopping criteria to be 1e-3\n",
    "Maximum number of iterations taken for the solvers to converge to be 100\n",
    "Q18. Enter the recall score you got for the given model (Take average as macro)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "80bd14c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KIIT0001\\OneDrive\\Desktop\\mlpractice\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7570872404378112"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(solver='sag', random_state=64, tol=1e-3, max_iter=100)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "recall_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892bc89f",
   "metadata": {},
   "source": [
    "Use Gridsearchcv with KNeighborsClassifier() being the estimator, accuracy as scoring parameter, cv value as 4 and consider [1,3,5,7] as \"number of neighbors\" to be examined.\n",
    "Consider following parameters for KNeighborsClassifier():\n",
    "Take metric as 'minkowski',\n",
    "Set P value as 2\n",
    "Keep other parameter values as default value.\n",
    "Q19. What is the best value of K you obtained using above instruction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "d7e47ebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 7}"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(metric='minkowski', p=2)\n",
    "param_grid = {\n",
    "    'n_neighbors': [1,3,5,7]\n",
    "}\n",
    "grid = GridSearchCV(knn, param_grid, cv=4)\n",
    "grid.fit(X_train, y_train)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70d7360",
   "metadata": {},
   "source": [
    "(Common Instruction for Q20 to Q23)\n",
    "Take DecisionTreeClassifier(random_state = 64) with GridSearchCV to train the model.Hyperparameter tuning to be done over the following parameters:\n",
    "Use criterion as 'entropy' or 'gini'\n",
    "Use splitter as 'random' or 'best'\n",
    "Use minimum number of samples per leaf as [2,4,6,8,10]\n",
    "Use maximum depth as [3,4,5,6]\n",
    "Use cross validation = 4\n",
    "Q20. Enter the value (up to 2 decimal points) of the 'score' on testing set using best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "fafc3f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84975"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state=64)\n",
    "param_grid = {\n",
    "    'criterion': ['entropy', 'gini'],\n",
    "    'splitter': ['random', 'best'],\n",
    "    'min_samples_leaf': [2,4,6,8,10],\n",
    "    'max_depth': [3,4,5,6]\n",
    "}\n",
    "grid = GridSearchCV(dt, param_grid, cv=4)\n",
    "grid.fit(X_train, y_train)\n",
    "best_model = grid.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1359f3f4",
   "metadata": {},
   "source": [
    "Q21. Enter the value of best max_depth of the model after training with GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "22c4daa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_['max_depth']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a385975e",
   "metadata": {},
   "source": [
    "Q22. Enter the value of best min_samples_leaf of the model after training with GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "4f89842f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_['min_samples_leaf']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e3cab1",
   "metadata": {},
   "source": [
    "Q23: What are the number of nodes in the optimal tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "1722d56b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.tree_.node_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0956a419",
   "metadata": {},
   "source": [
    "Take RandomForestClassifier (random state to be 64) with GridSearchCV to tune the number of decision trees with training set. The number of trees in forest can range from 5 to 10 (both inclusive).\n",
    "Q24. Mark the number of decision trees that will produce the best score on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "cd67ff4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 10}"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(random_state=64)\n",
    "param_grid = {\n",
    "    'n_estimators': [5,6,7,8,9,10]\n",
    "}\n",
    "grid = GridSearchCV(rfc, param_grid)\n",
    "grid.fit(X_train, y_train)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad3abd3",
   "metadata": {},
   "source": [
    "(Common Instructions for Q25,Q26)\n",
    "Take an adaboost model with following hyperparameter values and tune it using GridsearchCV.\n",
    "Use n_estimators as [10,20,30]\n",
    "random_state = 64\n",
    "Use learning_rate as [0.5,1,2]\n",
    "Take cv value= 4\n",
    "Q25. Train the 'model' using above instructions and enter the 'accuracy score' (up to 3 decimal points) on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "220d04db",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[249]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      3\u001b[39m param_grid = {\n\u001b[32m      4\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mn_estimators\u001b[39m\u001b[33m'\u001b[39m: [\u001b[32m10\u001b[39m,\u001b[32m20\u001b[39m,\u001b[32m30\u001b[39m],\n\u001b[32m      5\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mlearning_rate\u001b[39m\u001b[33m'\u001b[39m: [\u001b[32m0.5\u001b[39m,\u001b[32m1\u001b[39m,\u001b[32m2\u001b[39m]\n\u001b[32m      6\u001b[39m }\n\u001b[32m      7\u001b[39m grid = GridSearchCV(abc, param_grid, cv=\u001b[32m4\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mgrid\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m y_pred = grid.predict(X_test)\n\u001b[32m     10\u001b[39m accuracy_score(y_pred, y_test)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KIIT0001\\OneDrive\\Desktop\\mlpractice\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KIIT0001\\OneDrive\\Desktop\\mlpractice\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1045\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1046\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1047\u001b[39m     )\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1055\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KIIT0001\\OneDrive\\Desktop\\mlpractice\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1605\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1603\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1604\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1605\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KIIT0001\\OneDrive\\Desktop\\mlpractice\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:997\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    990\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    993\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    994\u001b[39m         )\n\u001b[32m    995\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1017\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1018\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1019\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1020\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KIIT0001\\OneDrive\\Desktop\\mlpractice\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KIIT0001\\OneDrive\\Desktop\\mlpractice\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KIIT0001\\OneDrive\\Desktop\\mlpractice\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KIIT0001\\OneDrive\\Desktop\\mlpractice\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:147\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config), warnings.catch_warnings():\n\u001b[32m    146\u001b[39m     warnings.filters = warning_filters\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KIIT0001\\OneDrive\\Desktop\\mlpractice\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:859\u001b[39m, in \u001b[36m_fit_and_score\u001b[39m\u001b[34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[39m\n\u001b[32m    857\u001b[39m         estimator.fit(X_train, **fit_params)\n\u001b[32m    858\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m859\u001b[39m         \u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    861\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    862\u001b[39m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[32m    863\u001b[39m     fit_time = time.time() - start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KIIT0001\\OneDrive\\Desktop\\mlpractice\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KIIT0001\\OneDrive\\Desktop\\mlpractice\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:167\u001b[39m, in \u001b[36mBaseWeightBoosting.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    164\u001b[39m sample_weight[zero_weight_mask] = \u001b[32m0.0\u001b[39m\n\u001b[32m    166\u001b[39m \u001b[38;5;66;03m# Boosting step\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m sample_weight, estimator_weight, estimator_error = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_boost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m    \u001b[49m\u001b[43miboost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[38;5;66;03m# Early termination\u001b[39;00m\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KIIT0001\\OneDrive\\Desktop\\mlpractice\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:570\u001b[39m, in \u001b[36mAdaBoostClassifier._boost\u001b[39m\u001b[34m(self, iboost, X, y, sample_weight, random_state)\u001b[39m\n\u001b[32m    531\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Implement a single boost.\u001b[39;00m\n\u001b[32m    532\u001b[39m \n\u001b[32m    533\u001b[39m \u001b[33;03mPerform a single boost according to the discrete SAMME algorithm and return the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    566\u001b[39m \u001b[33;03m    If None then boosting has terminated early.\u001b[39;00m\n\u001b[32m    567\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    568\u001b[39m estimator = \u001b[38;5;28mself\u001b[39m._make_estimator(random_state=random_state)\n\u001b[32m--> \u001b[39m\u001b[32m570\u001b[39m \u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    572\u001b[39m y_predict = estimator.predict(X)\n\u001b[32m    574\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m iboost == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KIIT0001\\OneDrive\\Desktop\\mlpractice\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KIIT0001\\OneDrive\\Desktop\\mlpractice\\.venv\\Lib\\site-packages\\sklearn\\tree\\_classes.py:1024\u001b[39m, in \u001b[36mDecisionTreeClassifier.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, check_input)\u001b[39m\n\u001b[32m    993\u001b[39m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    994\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight=\u001b[38;5;28;01mNone\u001b[39;00m, check_input=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m    995\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[32m    996\u001b[39m \n\u001b[32m    997\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1021\u001b[39m \u001b[33;03m        Fitted estimator.\u001b[39;00m\n\u001b[32m   1022\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1028\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1029\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1030\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KIIT0001\\OneDrive\\Desktop\\mlpractice\\.venv\\Lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[39m, in \u001b[36mBaseDecisionTree._fit\u001b[39m\u001b[34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[39m\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    462\u001b[39m     builder = BestFirstTreeBuilder(\n\u001b[32m    463\u001b[39m         splitter,\n\u001b[32m    464\u001b[39m         min_samples_split,\n\u001b[32m   (...)\u001b[39m\u001b[32m    469\u001b[39m         \u001b[38;5;28mself\u001b[39m.min_impurity_decrease,\n\u001b[32m    470\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m472\u001b[39m \u001b[43mbuilder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.n_outputs_ == \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    475\u001b[39m     \u001b[38;5;28mself\u001b[39m.n_classes_ = \u001b[38;5;28mself\u001b[39m.n_classes_[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "abc = AdaBoostClassifier(random_state=64)\n",
    "param_grid = {\n",
    "    'n_estimators': [10,20,30],\n",
    "    'learning_rate': [0.5,1,2]\n",
    "}\n",
    "grid = GridSearchCV(abc, param_grid, cv=4)\n",
    "grid.fit(X_train, y_train)\n",
    "y_pred = grid.predict(X_test)\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35464f79",
   "metadata": {},
   "source": [
    "Q26. Enter the value of best n_estimators of the model after training with GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f9fa28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 1, 'n_estimators': 30}"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef43008",
   "metadata": {},
   "source": [
    "Apply GridsearchCV and support vector machine (SVM)(kernel':('linear', 'rbf'), 'C':[1, 10]) on the training dataset X_train, y_train and calculate the best value of C and kernel.\n",
    "Q27. Which of the following options represent the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b754a596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC()\n",
    "param_grid={\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'C': [1,10]\n",
    "}\n",
    "grid = GridSearchCV(svm, param_grid)\n",
    "grid.fit(X_train, y_train)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ca9700",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
