{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d0be4c9",
   "metadata": {},
   "source": [
    "Data preproccessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "6d71a556",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "771ea10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "8c0d70b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Copy of V1 (pre).csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33939e85",
   "metadata": {},
   "source": [
    "How many total number of rows and columns are there in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "8b63dd66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 15)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c86994",
   "metadata": {},
   "source": [
    "Is there any Missing values in the given dataset ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "6c8c274f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sum()\n",
    "df.isna().sum().sum() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cf328c",
   "metadata": {},
   "source": [
    "Check all \" ?\" symbol in the dataset and replace it with \"np.nan\" value . Which of the columns in the dataset have null values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "f50e9ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               False\n",
       "workclass         False\n",
       "fnlwgt            False\n",
       "education         False\n",
       "education-num     False\n",
       "marital-status    False\n",
       "occupation        False\n",
       "relationship      False\n",
       "race              False\n",
       "sex               False\n",
       "capital-gain      False\n",
       "capital-loss      False\n",
       "hours-per-week    False\n",
       "native-country    False\n",
       "IncomeGroup       False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.replace(\" ?\", np.nan)\n",
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7542b0",
   "metadata": {},
   "source": [
    "What fraction of total samples (in percentage) have missing value in occupation column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "d06b96df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(5.7)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['occupation'].replace(\" ?\", np.nan).isnull().mean()*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a760843",
   "metadata": {},
   "source": [
    " What fraction of total samples(In percentage) have income <= 50k in the given dataset? (round the value upto 2 decimal places)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b455783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(76.51)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['IncomeGroup'].eq(\" <=50K\").mean() * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2043ea34",
   "metadata": {},
   "source": [
    "What is the mean age of the samples given in the dataset(mark the closest integer from the given options)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "f434987e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(38.553)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = df.age.mean()\n",
    "mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6aa4045",
   "metadata": {},
   "source": [
    "How many people have completed their education upto \"Preschool\" only ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "2dbf237e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' 7th-8th', ' 11th', ' Bachelors', ' HS-grad', ' Some-college',\n",
       "       ' Masters', ' Assoc-voc', ' Doctorate', ' 5th-6th', ' 10th',\n",
       "       ' 12th', ' Assoc-acdm', ' Prof-school', ' 9th', ' 1st-4th',\n",
       "       ' Preschool'], dtype=object)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.education.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "a1404a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_preschool = df[df['education'] == ' Preschool'].shape[0]\n",
    "count_preschool\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f62f0f",
   "metadata": {},
   "source": [
    "What is the correlation cofficient between column \"education-num\" and column \"capital-gain\" ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "294d4c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.12456727883397221)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_value = df['education-num'].corr(df['capital-gain'])\n",
    "corr_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e519d123",
   "metadata": {},
   "source": [
    "Apply SimpleImputer with strategy = 'most_frequent' to replace all NaN value by mode of respective column in the original dataset.(Use this updated dataset only for all further questions)\n",
    "Q10. What is the mode of 'occupation' column of updated datset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "e4d28c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Prof-specialty\n"
     ]
    }
   ],
   "source": [
    "st = SimpleImputer(strategy='most_frequent')\n",
    "st.fit_transform(df)\n",
    "occ = df.occupation.mode()[0]\n",
    "print(occ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f81f57",
   "metadata": {},
   "source": [
    "Split the dataset into X1, X2 and y, where X1 contains all Numerical features, X2 contains all categorical features(except \"IncomeGroup\") and save 'IncomeGroup' column in y variable. Then apply OneHotEncoder on the categorical features(X2) with option (sparse = False) and StandardScaler on the numerical features (X2).\n",
    "Q11. What is the total number of columns in X1 and X2 variables respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "31a73135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('IncomeGroup', axis=1)\n",
    "y = df['IncomeGroup']\n",
    "numeric_cols = X.select_dtypes(exclude=\"object\").columns\n",
    "categorical_cols = X.select_dtypes(include=\"object\").columns\n",
    "\n",
    "X1 = X[numeric_cols]     \n",
    "X2 = X[categorical_cols]      \n",
    "\n",
    "print(len(X1.columns))\n",
    "print(len(X2.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bc731b",
   "metadata": {},
   "source": [
    "Apply StandardScaler on the X1 data and OneHotEncoder on X2 data with option (sparse = False).\n",
    "Q12. What are the data types of X1 and X2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "d20ff684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X1_scaled = scaler.fit_transform(X1)\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "X2_encoded = encoder.fit_transform(X2)\n",
    "\n",
    "print(type(X1_scaled))\n",
    "print(type(X2_encoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630a2c13",
   "metadata": {},
   "source": [
    "Concatenate X1 and X2 and call it X( Keep axis = 1) and then Convert X to a dataframe.\n",
    "Q13. What is the new shape of resultant X?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "ea61068f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 108)\n"
     ]
    }
   ],
   "source": [
    "X = np.concatenate([X1_scaled, X2_encoded], axis=1)\n",
    "X = pd.DataFrame(X)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfde4a0",
   "metadata": {},
   "source": [
    "Model Building\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd212c9c",
   "metadata": {},
   "source": [
    " Split the dataset into training and validation dataset into 80:20 ratio while keeping random_state =64. what is the shape of the y_train dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "88ccece1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000,)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=64)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf6c39d",
   "metadata": {},
   "source": [
    "Instantiate a perceptron classifier that with following parameters:\n",
    "Fit the intercept\n",
    "Put warm start to be False\n",
    "Fit this perceptron model with the training dataset and calculate the accuracy score for training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "51072c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8055"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per = Perceptron(fit_intercept=True, warm_start=False)\n",
    "per.fit(X_train, y_train)\n",
    "y_pred=per.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c812880b",
   "metadata": {},
   "source": [
    "Q16. Create a new Perceptron(random_state=42) object with given settings in the instrunctions and train it on training set . What is the value of bias (intercept) (upto 1 decimal point) ?\n",
    "Set early stopping and fit intercept to be True\n",
    "Put warm start to be False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "06ae3d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-8.])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per1 = Perceptron(random_state=42, early_stopping=True, fit_intercept=True, warm_start=False)\n",
    "per1.fit(X_train, y_train)\n",
    "per1.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25003d8",
   "metadata": {},
   "source": [
    "Use SGDClassifier on the training dataset (X_train and y_train) to train the model. Use the following parameters:\n",
    "log is the loss function to be used\n",
    "apply ridge regularization,\n",
    "maximum number of passes over the training data is 10\n",
    "initial learning rate is 0.01,\n",
    "regularization rate value is 0.001,\n",
    "learning rate should not change during training.\n",
    "Take random_state=64.\n",
    "Set warm_state as False\n",
    "Note : Please ignore the convergence warning.\n",
    "\n",
    "Q17. Based on this operation, calculate and enter the correct value of accuracy (Upto 4 decimal points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "bdf07527",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "dcaaab62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KIIT0001\\OneDrive\\Desktop\\mlpractice\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.849"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd = SGDClassifier(loss='log_loss', penalty='l2', max_iter=10, eta0=0.01, alpha=0.001, learning_rate='constant', random_state=64, warm_start=False)\n",
    "sgd.fit(X_train, y_train)\n",
    "y_pred = sgd.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4898ec2",
   "metadata": {},
   "source": [
    "Take LogisticRegression estimator with following parameters for fitting on the training dataset:\n",
    "Use sag as solver\n",
    "Set random state to be equal to 64\n",
    "Tolerance for stopping criteria to be 1e-3\n",
    "Maximum number of iterations taken for the solvers to converge to be 100\n",
    "Q18. Enter the recall score you got for the given model (Take average as macro)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "80bd14c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[199]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m lr = LogisticRegression(solver=\u001b[33m'\u001b[39m\u001b[33msag\u001b[39m\u001b[33m'\u001b[39m, random_state=\u001b[32m64\u001b[39m, tol=\u001b[32m1e-3\u001b[39m, max_iter=\u001b[32m100\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mlr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m y_pred = lr.predict(X_test)\n\u001b[32m      4\u001b[39m recall_score(y_test, y_pred, average=\u001b[33m'\u001b[39m\u001b[33mmacro\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KIIT0001\\OneDrive\\Desktop\\mlpractice\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KIIT0001\\OneDrive\\Desktop\\mlpractice\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1384\u001b[39m, in \u001b[36mLogisticRegression.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m   1381\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1382\u001b[39m     n_threads = \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1384\u001b[39m fold_coefs_ = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprefer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1385\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1386\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1387\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1388\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpos_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1389\u001b[39m \u001b[43m        \u001b[49m\u001b[43mCs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mC_\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1390\u001b[39m \u001b[43m        \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1391\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1392\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1393\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1394\u001b[39m \u001b[43m        \u001b[49m\u001b[43msolver\u001b[49m\u001b[43m=\u001b[49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1395\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1396\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1397\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1398\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1399\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1400\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcoef\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1401\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpenalty\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1402\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1403\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1404\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1405\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1406\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclasses_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1407\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1409\u001b[39m fold_coefs_, _, n_iter_ = \u001b[38;5;28mzip\u001b[39m(*fold_coefs_)\n\u001b[32m   1410\u001b[39m \u001b[38;5;28mself\u001b[39m.n_iter_ = np.asarray(n_iter_, dtype=np.int32)[:, \u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KIIT0001\\OneDrive\\Desktop\\mlpractice\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KIIT0001\\OneDrive\\Desktop\\mlpractice\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KIIT0001\\OneDrive\\Desktop\\mlpractice\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KIIT0001\\OneDrive\\Desktop\\mlpractice\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:147\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config), warnings.catch_warnings():\n\u001b[32m    146\u001b[39m     warnings.filters = warning_filters\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KIIT0001\\OneDrive\\Desktop\\mlpractice\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:560\u001b[39m, in \u001b[36m_logistic_regression_path\u001b[39m\u001b[34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[39m\n\u001b[32m    557\u001b[39m         alpha = (\u001b[32m1.0\u001b[39m / C) * (\u001b[32m1\u001b[39m - l1_ratio)\n\u001b[32m    558\u001b[39m         beta = (\u001b[32m1.0\u001b[39m / C) * l1_ratio\n\u001b[32m--> \u001b[39m\u001b[32m560\u001b[39m     w0, n_iter_i, warm_start_sag = \u001b[43msag_solver\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    561\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[43m        \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    565\u001b[39m \u001b[43m        \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    566\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    568\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    569\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    570\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    571\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    572\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    573\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwarm_start_sag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    574\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_saga\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msolver\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msaga\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    575\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    577\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    578\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    579\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msolver must be one of \u001b[39m\u001b[33m{\u001b[39m\u001b[33m'\u001b[39m\u001b[33mliblinear\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mlbfgs\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    580\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mnewton-cg\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33msag\u001b[39m\u001b[33m'\u001b[39m\u001b[33m}, got \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m instead\u001b[39m\u001b[33m\"\u001b[39m % solver\n\u001b[32m    581\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KIIT0001\\OneDrive\\Desktop\\mlpractice\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:323\u001b[39m, in \u001b[36msag_solver\u001b[39m\u001b[34m(X, y, sample_weight, loss, alpha, beta, max_iter, tol, verbose, random_state, check_input, max_squared_sum, warm_start_mem, is_saga)\u001b[39m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mZeroDivisionError\u001b[39;00m(\n\u001b[32m    318\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCurrent sag implementation does not handle \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    319\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mthe case step_size * alpha_scaled == 1\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    320\u001b[39m     )\n\u001b[32m    322\u001b[39m sag = sag64 \u001b[38;5;28;01mif\u001b[39;00m X.dtype == np.float64 \u001b[38;5;28;01melse\u001b[39;00m sag32\n\u001b[32m--> \u001b[39m\u001b[32m323\u001b[39m num_seen, n_iter_ = \u001b[43msag\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    324\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcoef_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    326\u001b[39m \u001b[43m    \u001b[49m\u001b[43mintercept_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    327\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstep_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m    \u001b[49m\u001b[43malpha_scaled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta_scaled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m    \u001b[49m\u001b[43msum_gradient_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgradient_memory_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    338\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseen_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_seen_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    340\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[43m    \u001b[49m\u001b[43mintercept_sum_gradient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[43m    \u001b[49m\u001b[43mintercept_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_saga\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    344\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    345\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_iter_ == max_iter:\n\u001b[32m    348\u001b[39m     warnings.warn(\n\u001b[32m    349\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe max_iter was reached which means the coef_ did not converge\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    350\u001b[39m         ConvergenceWarning,\n\u001b[32m    351\u001b[39m     )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(solver='sag', random_state=64, tol=1e-3, max_iter=100)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "recall_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892bc89f",
   "metadata": {},
   "source": [
    "Use Gridsearchcv with KNeighborsClassifier() being the estimator, accuracy as scoring parameter, cv value as 4 and consider [1,3,5,7] as \"number of neighbors\" to be examined.\n",
    "Consider following parameters for KNeighborsClassifier():\n",
    "Take metric as 'minkowski',\n",
    "Set P value as 2\n",
    "Keep other parameter values as default value.\n",
    "Q19. What is the best value of K you obtained using above instruction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e47ebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 7}"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(metric='minkowski', p=2)\n",
    "param_grid = {\n",
    "    'n_neighbors': [1,3,5,7]\n",
    "}\n",
    "grid = GridSearchCV(knn, param_grid, cv=4)\n",
    "grid.fit(X_train, y_train)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70d7360",
   "metadata": {},
   "source": [
    "(Common Instruction for Q20 to Q23)\n",
    "Take DecisionTreeClassifier(random_state = 64) with GridSearchCV to train the model.Hyperparameter tuning to be done over the following parameters:\n",
    "Use criterion as 'entropy' or 'gini'\n",
    "Use splitter as 'random' or 'best'\n",
    "Use minimum number of samples per leaf as [2,4,6,8,10]\n",
    "Use maximum depth as [3,4,5,6]\n",
    "Use cross validation = 4\n",
    "Q20. Enter the value (up to 2 decimal points) of the 'score' on testing set using best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafc3f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84975"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state=64)\n",
    "param_grid = {\n",
    "    'criterion': ['entropy', 'gini'],\n",
    "    'splitter': ['random', 'best'],\n",
    "    'min_samples_leaf': [2,4,6,8,10],\n",
    "    'max_depth': [3,4,5,6]\n",
    "}\n",
    "grid = GridSearchCV(dt, param_grid, cv=4)\n",
    "grid.fit(X_train, y_train)\n",
    "best_model = grid.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1359f3f4",
   "metadata": {},
   "source": [
    "Q21. Enter the value of best max_depth of the model after training with GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c4daa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_['max_depth']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a385975e",
   "metadata": {},
   "source": [
    "Q22. Enter the value of best min_samples_leaf of the model after training with GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f89842f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_['min_samples_leaf']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e3cab1",
   "metadata": {},
   "source": [
    "Q23: What are the number of nodes in the optimal tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1722d56b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.tree_.node_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0956a419",
   "metadata": {},
   "source": [
    "Take RandomForestClassifier (random state to be 64) with GridSearchCV to tune the number of decision trees with training set. The number of trees in forest can range from 5 to 10 (both inclusive).\n",
    "Q24. Mark the number of decision trees that will produce the best score on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd67ff4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 10}"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(random_state=64)\n",
    "param_grid = {\n",
    "    'n_estimators': [5,6,7,8,9,10]\n",
    "}\n",
    "grid = GridSearchCV(rfc, param_grid)\n",
    "grid.fit(X_train, y_train)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad3abd3",
   "metadata": {},
   "source": [
    "(Common Instructions for Q25,Q26)\n",
    "Take an adaboost model with following hyperparameter values and tune it using GridsearchCV.\n",
    "Use n_estimators as [10,20,30]\n",
    "random_state = 64\n",
    "Use learning_rate as [0.5,1,2]\n",
    "Take cv value= 4\n",
    "Q25. Train the 'model' using above instructions and enter the 'accuracy score' (up to 3 decimal points) on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220d04db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85175"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "abc = AdaBoostClassifier(random_state=64)\n",
    "param_grid = {\n",
    "    'n_estimators': [10,20,30],\n",
    "    'learning_rate': [0.5,1,2]\n",
    "}\n",
    "grid = GridSearchCV(abc, param_grid, cv=4)\n",
    "grid.fit(X_train, y_train)\n",
    "y_pred = grid.predict(X_test)\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35464f79",
   "metadata": {},
   "source": [
    "Q26. Enter the value of best n_estimators of the model after training with GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f9fa28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 1, 'n_estimators': 30}"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef43008",
   "metadata": {},
   "source": [
    "Apply GridsearchCV and support vector machine (SVM)(kernel':('linear', 'rbf'), 'C':[1, 10]) on the training dataset X_train, y_train and calculate the best value of C and kernel.\n",
    "Q27. Which of the following options represent the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b754a596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC()\n",
    "param_grid={\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'C': [1,10]\n",
    "}\n",
    "grid = GridSearchCV(svm, param_grid)\n",
    "grid.fit(X_train, y_train)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ca9700",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
